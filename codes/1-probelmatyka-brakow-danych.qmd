---
title: "1. Problematyka braków danych"
format: 
  html:
    self-contained: true
    number-sections: true
    toc: true
    toc-title: "Spis treści"
editor: source
---

# Wizualizacja braków danych

::: panel-tabset
## R

```{r}
# Ustawiamy ziarno losowości dla powtarzalności wyników
set.seed(123)

# Wczytanie biblioteki do obsługi polskich znaków w PDF
library(xtable)
pdf.options(encoding = "CP1250")

# Generowanie danych
n <- 1000  # liczba obserwacji
x <- rnorm(n, mean = 50, sd = 10)  # X z rozkładu normalnego
y <- 5 * x + rnorm(n, mean = 0, sd = 20)  # Wzmocniona zależność Y od X

# Funkcja do generowania braków danych
generate_missing <- function(y, x, mechanism, prob = 0.3) {
  n <- length(y)
  missing <- rep(FALSE, n)
  
  if (mechanism == "MCAR") {
    missing <- runif(n) < prob
  } else if (mechanism == "MAR") {
    prob_missing <- plogis(2*scale(x))  # Prawdopodobieństwo braku zależy od X
    missing <- runif(n) < prob_missing
  } else if (mechanism == "NMAR") {
    prob_missing <- plogis(2*scale(y))  # Prawdopodobieństwo braku zależy od Y
    missing <- runif(n) < prob_missing
  }
  
  y[missing] <- NA
  return(y)
}

# Generowanie braków danych dla każdego mechanizmu
y_mcar <- generate_missing(y, x, "MCAR")
y_mar <- generate_missing(y, x, "MAR")
y_nmar <- generate_missing(y, x, "NMAR")

# Funkcja do tworzenia wykresu porównawczego rozkładów gęstości
plot_density_comparison <- function(y_full, y_obs, title, y_max) {
  dens_full <- density(y_full)
  dens_obs <- density(y_obs[!is.na(y_obs)])
  
  plot(dens_full, main = title, xlab = "Y", ylab = "Gęstość",
       col = "blue", lwd = 2, cex.main = 1, cex.lab = 1, cex.axis = 1,
       ylim = c(0, y_max))
  lines(dens_obs, col = "red", lwd = 2)
  legend("topright", legend = c("Pełne dane", "Obserwowane dane"),
         col = c("blue", "red"), lwd = 2,  cex = 1)
}

# Obliczenie maksymalnej wartości gęstości dla wszystkich przypadków
y_max <- max(c(
  max(density(y)$y),
  max(density(y_mcar[!is.na(y_mcar)])$y),
  max(density(y_mar[!is.na(y_mar)])$y),
  max(density(y_nmar[!is.na(y_nmar)])$y)
))

# Tworzenie wykresów
pdf("fig-missing-examples.pdf", width = 12, height = 4)
par(mfrow = c(1, 3), oma = c(0, 0, 2, 0), mar = c(4, 4, 2, 2))

plot_density_comparison(y, y_mcar, "MCAR", y_max)
plot_density_comparison(y, y_mar, "MAR", y_max)
plot_density_comparison(y, y_nmar, "NMAR", y_max)

dev.off()

# Tworzymy ramkę danych z wynikami
results <- data.frame(
  Statystyka = c("Procent brakujących danych", "Średnia Y", "Odchylenie standardowe Y", "Korelacja między X i Y"),
  Pelne_dane = c(0, mean(y), sd(y), cor(x, y)),
  MCAR = c(mean(is.na(y_mcar)) * 100, mean(y_mcar, na.rm = TRUE), sd(y_mcar, na.rm = TRUE), cor(x, y_mcar, use = "complete.obs")),
  MAR = c(mean(is.na(y_mar)) * 100, mean(y_mar, na.rm = TRUE), sd(y_mar, na.rm = TRUE), cor(x, y_mar, use = "complete.obs")),
  NMAR = c(mean(is.na(y_nmar)) * 100, mean(y_nmar, na.rm = TRUE), sd(y_nmar, na.rm = TRUE), cor(x, y_nmar, use = "complete.obs"))
)

# Tworzymy tabelę xtable
xtable_results <- xtable(results, 
                         caption = "Porównanie statystyk dla różnych mechanizmów braków danych",
                         label = "tab:missing-data-stats",
                         digits = 2)

# Generujemy kod LaTeX
latex_code <- print(xtable_results, 
                    include.rownames = FALSE,
                    floating = TRUE,
                    table.placement = "htbp",
                    caption.placement = "top",
                    print.results = FALSE)

# Wyświetlamy kod LaTeX
cat(latex_code)
```

## Python

```{python}
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy import stats
from tabulate import tabulate
from scipy.stats import gaussian_kde

# Ustawiamy ziarno losowości dla powtarzalności wyników
np.random.seed(123)

# Generowanie danych
n = 1000  # liczba obserwacji
x = np.random.normal(loc=50, scale=10, size=n)  # X z rozkładu normalnego
y = 5 * x + np.random.normal(loc=0, scale=20, size=n)  # Wzmocniona zależność Y od X

# Funkcja do generowania braków danych
def generate_missing(y, x, mechanism, prob=0.3):
    n = len(y)
    missing = np.full(n, False)
    
    if mechanism == "MCAR":
        missing = np.random.random(n) < prob
    elif mechanism == "MAR":
        prob_missing = stats.logistic.cdf(2 * stats.zscore(x))  # Prawdopodobieństwo braku zależy od X
        missing = np.random.random(n) < prob_missing
    elif mechanism == "NMAR":
        prob_missing = stats.logistic.cdf(2 * stats.zscore(y))  # Prawdopodobieństwo braku zależy od Y
        missing = np.random.random(n) < prob_missing
    
    y_missing = y.copy()
    y_missing[missing] = np.nan
    return y_missing

# Generowanie braków danych dla każdego mechanizmu
y_mcar = generate_missing(y, x, "MCAR")
y_mar = generate_missing(y, x, "MAR")
y_nmar = generate_missing(y, x, "NMAR")

# Funkcja do tworzenia wykresu porównawczego rozkładów gęstości
def plot_density_comparison(y_full, y_obs, title, ax):
    kde_full = gaussian_kde(y_full)
    kde_obs = gaussian_kde(y_obs[~np.isnan(y_obs)])
    
    x_range = np.linspace(min(y_full), max(y_full), 100)
    
    ax.plot(x_range, kde_full(x_range), color="blue", label="Pełne dane")
    ax.plot(x_range, kde_obs(x_range), color="red", label="Obserwowane dane")
    ax.set_title(title)
    ax.set_xlabel("Y")
    ax.set_ylabel("Gęstość")
    ax.legend(loc='upper right')

# Tworzenie wykresów
fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4))
plot_density_comparison(y, y_mcar, "MCAR", ax1)
plot_density_comparison(y, y_mar, "MAR", ax2)
plot_density_comparison(y, y_nmar, "NMAR", ax3)
plt.tight_layout()
plt.savefig("fig-missing-examples-py.pdf")
plt.close()

# Tworzenie ramki danych z wynikami
results = pd.DataFrame({
    "Statystyka": ["Procent brakujących danych", "Średnia Y", "Odchylenie standardowe Y", "Korelacja między X i Y"],
    "Pełne dane": [0, np.mean(y), np.std(y), np.corrcoef(x, y)[0, 1]],
    "MCAR": [np.mean(np.isnan(y_mcar)) * 100, np.nanmean(y_mcar), np.nanstd(y_mcar), np.corrcoef(x[~np.isnan(y_mcar)], y_mcar[~np.isnan(y_mcar)])[0, 1]],
    "MAR": [np.mean(np.isnan(y_mar)) * 100, np.nanmean(y_mar), np.nanstd(y_mar), np.corrcoef(x[~np.isnan(y_mar)], y_mar[~np.isnan(y_mar)])[0, 1]],
    "NMAR": [np.mean(np.isnan(y_nmar)) * 100, np.nanmean(y_nmar), np.nanstd(y_nmar), np.corrcoef(x[~np.isnan(y_nmar)], y_nmar[~np.isnan(y_nmar)])[0, 1]]
})

# Zaokrąglamy wszystkie wartości numeryczne do 2 miejsc po przecinku
results.iloc[:, 1:] = results.iloc[:, 1:].round(2)

# Generujemy kod LaTeX
latex_code = tabulate(results, headers='keys', tablefmt='latex_booktabs', showindex=False)

# Dodajemy nagłówek i stopkę tabeli LaTeX
latex_code = f"""
\\begin{{table}}[htbp]
\\centering
\\caption{{Porównanie statystyk dla różnych mechanizmów braków danych}}
\\label{{tab:missing-data-stats}}
{latex_code}
\\end{{table}}
"""

# Wyświetlamy kod LaTeX
print(latex_code)
```
:::


Wykres na podstawie pracy Riddles, M. K., Kim, J. K., \& Im, J. (2016). A propensity-score-adjustment method for nonignorable nonresponse. Journal of Survey Statistics and Methodology, 4(2), 215-245. (tablica 9).

::: panel-tabset

## R

```{r}
# Load required libraries
library(ggplot2)
library(dplyr)
library(tidyr)
library(patchwork)

# Create the dataset
data <- data.frame(
  Gender = rep(c("Male", "Female"), each = 4),
  Age_group = rep(c("20-29", "30-39", "40-49", "50+"), 2),
  Voted_A = c(93, 104, 146, 560, 106, 129, 170, 501),
  Voted_B = c(115, 233, 295, 350, 159, 242, 262, 218),
  Other = c(4, 8, 5, 3, 8, 5, 5, 7),
  Refusal = c(28, 82, 49, 174, 62, 70, 69, 211)
)

# Process the data
data_processed <- data |>
  mutate(Voted = Voted_A + Voted_B + Other,
         Total = Voted + Refusal) |>
  pivot_longer(cols = c(Voted, Refusal), names_to = "Category", values_to = "Count") |>
  group_by(Gender, Age_group) |>
  mutate(Percentage = Count / sum(Count) * 100)

# Function to create a basic plot
create_plot <- function(data, x_var, title) {
  ggplot(data, aes(x = .data[[x_var]], y = Percentage, fill = Category)) +
    geom_bar(stat = "identity", color = "black") + 
    scale_fill_brewer(type = "seq", palette = "Paired") + 
    #scale_fill_manual(values = c("Voted" = "#4CAF50", "Refusal" = "#FFA500")) +
    labs(title = title, x = x_var, y = "Percentage") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    scale_y_continuous(labels = scales::percent_format(scale = 1))
}

# Create the combined plot
plot_combined <- create_plot(data_processed, "Age_group", "By Age Group and Gender") +
  facet_wrap(~ Gender, scales = "free_x", nrow = 1)  +
  labs(x = "")

# Create the age group plot
plot_age <- data_processed %>%
  group_by(Age_group, Category) %>%
  summarise(Percentage = sum(Count) / sum(Total) * 100, .groups = "drop") %>%
  create_plot("Age_group", "By Age Group") +
  labs(x = "")

# Create the gender plot
plot_gender <- data_processed %>%
  group_by(Gender, Category) %>%
  summarise(Percentage = sum(Count) / sum(Total) * 100, .groups = "drop") %>%
  create_plot("Gender", "By Gender") +
  labs(x = "")

# Combine all plots using patchwork
final_plot <- (plot_combined + plot_age + plot_gender) +
  plot_layout(ncol = 3, widths = c(2, 1, 1)) +
  plot_annotation(
    title = "Exit Poll Results for Gangdong-Gap",
    theme = theme(plot.title = element_text(hjust = 0.5, size = 16))
  ) + plot_layout(guides = "collect")

# Save the combined plot as a PDF
ggsave("fig-riddles.pdf", final_plot, width = 10, height = 7, units = "in")
```

## Python

TBA

:::

# Braki danych w pakietach statystycznych

## Kodowanie braków danych

::: panel-tabset
## R

```{r}
x1 <- c(1,2,3,NA)
summary(x1)
```

```{r}
table(x1)
```

```{r}
table(x1, useNA = "ifany")
```

```{r}
mean(x1)
```

```{r}
mean(x1, na.rm = T)
```

```{r}
na.omit(x1)
```

```{r}
x2 <- c(1,2,3, NA, NaN)
```

```{r}
summary(x2)
```

```{r}
mean(x2, na.rm=T)
```

```{r}
table(x2)
table(x2, useNA = "ifany")
```

```{r}
na.omit(x2)
```

## Python

```{python}
x1 = pd.Series([1, 2, 3, np.nan])
x1.describe()
```

```{python}
x1.value_counts()
```

```{python}
x1.value_counts(dropna=False)
```


```{python}
x1.mean()
```


```{python}
x1.mean(skipna=True)
```


```{python}
x1.dropna()
```



:::

## Praca z brakami danych

### Dane wczytywane z plików

::: panel-tabset
## R

```{r}
dane <- read.csv("../data/plik-przyklad.csv")
head(dane)
```

```{r}
tail(dane)
```

Plik zawiera różne sposoby kodowania braków danych? Jakie? 


## Python

:::

### Dane ankietowe

W tym miejscu omówiony zostanie zbiór danych z Badania Kapitału Ludzkiego.

::: panel-tabset
## R

```{r}
library(haven)
```

```{r}
doc <- read_spss("https://www.parp.gov.pl/images/publications/BKL/nowy-uklad/Baza_danych_z_badania_ludnoci_BKL_edycja_2021_SAV-SPSS.sav")
str(doc$m9_1,2)
```

```{r}
table(doc$m9_1)
table(doc$m9_1, useNA = "ifany")
```

```{r}
doc <- read_spss("https://www.parp.gov.pl/images/publications/BKL/nowy-uklad/Baza_danych_z_badania_ludnoci_BKL_edycja_2021_SAV-SPSS.sav", user_na = T)
str(doc$m9_1,2)
```

```{r}
table(doc$m9_1)
table(doc$m9_1, useNA = "ifany")
```
## Python

```{python}
import pandas as pd
import pyreadstat
import numpy as np
import requests
import os
```

```{python}
url = "https://www.parp.gov.pl/images/publications/BKL/nowy-uklad/Baza_danych_z_badania_ludnoci_BKL_edycja_2021_SAV-SPSS.sav"
response = requests.get(url)
file_name = "../data/downloaded_data.sav"
with open(file_name, 'wb') as file:
    file.write(response.content)
```

```{python}
df, meta = pyreadstat.read_sav(file_name)
# Print structure of m9_1
print(df['m9_1'].dtype)
print(df['m9_1'].head(2))

```


```{python}
print(df['m9_1'].value_counts())
print(df['m9_1'].value_counts(dropna=False))
```


```{python}
df2, meta2 = pyreadstat.read_sav(file_name, user_missing=True, usecols = ["m9_1"])
print(df2['m9_1'].dtype)
print(df2['m9_1'].head(2))
```

```{python}
print(df2['m9_1'].value_counts())
print(df2['m9_1'].value_counts(dropna=False))
```

:::



